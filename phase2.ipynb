{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from PIL import Image\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix, roc_curve, roc_auc_score, auc\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import joblib\n",
        "from sklearn.decomposition import PCA\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.multiclass import OneVsRestClassifier\n"
      ],
      "metadata": {
        "id": "HrmjC5CxaJ-2"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "O95KvK7tIvMo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e587725-a9a6-47a4-fad8-9730c47cfcb0"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://thor.robots.ox.ac.uk/datasets/pets/images.tar.gz to oxford-iiit-pet/images.tar.gz\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 791918971/791918971 [00:37<00:00, 21248457.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting oxford-iiit-pet/images.tar.gz to oxford-iiit-pet\n",
            "Downloading https://thor.robots.ox.ac.uk/datasets/pets/annotations.tar.gz to oxford-iiit-pet/annotations.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 19173078/19173078 [00:01<00:00, 10695350.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting oxford-iiit-pet/annotations.tar.gz to oxford-iiit-pet\n",
            "Number of batches in train loader: 46\n",
            "Number of batches in test loader: 46\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import OxfordIIITPet\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# transforms.Compose: Composes several transforms together. Here, it resizes images to (224, 224) and converts them to PyTorch tensors.\n",
        "# Define the data transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Download and load the Oxford-IIIT Pet dataset\n",
        "dataset = OxfordIIITPet(root='./', transform=transform, download=True)\n",
        "\n",
        "# Split the dataset into train and test sets (80% train, 20% test)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "# Define the data loader with different batches\n",
        "batch_size_train = 64\n",
        "batch_size_test = 16\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size_train, shuffle=True, num_workers=4)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size_test, shuffle=False, num_workers=4)\n",
        "\n",
        "# Check the length of train and test loaders\n",
        "print(\"Number of batches in train loader:\", len(train_loader))\n",
        "print(\"Number of batches in test loader:\", len(test_loader))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAsNyPBC144B"
      },
      "source": [
        "The code:\n",
        "\n",
        "```python\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size_train, shuffle=True, num_workers=4)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size_test, shuffle=False, num_workers=4)\n",
        "```\n",
        "\n",
        "creates data loaders for the training and testing sets using PyTorch's `DataLoader` class. Here's what each parameter does:\n",
        "\n",
        "- `train_dataset` and `test_dataset`: These are the training and testing datasets, respectively.\n",
        "\n",
        "- `batch_size`: Specifies the number of samples in each batch during training or testing. `batch_size_train` and `batch_size_test` are the values defined earlier.\n",
        "\n",
        "- `shuffle`: When set to `True`, the DataLoader shuffles the data at the beginning of each epoch during training. Shuffling helps in preventing the model from learning the order of examples and improves generalization. For testing (`shuffle=False`), the data is not shuffled to ensure consistent evaluation.\n",
        "\n",
        "- `num_workers`: Specifies the number of worker processes to use for data loading. It allows loading data in parallel using multiple processes, which can speed up the data loading process. In this case, `num_workers=4` means that four parallel worker processes will be used to load the data.\n",
        "\n",
        "So, this code creates two data loaders (`train_loader` and `test_loader`) with the specified batch sizes and settings, which can be used to iterate over batches of data during the training and testing phases of a deep learning model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pgQRjq21Nkn1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc1a2e41-bf63-47dc-8dc4-a2006f1e7868"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of batches in train loader: 46\n",
            "Number of batches in test loader: 46\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import OxfordIIITPet\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from sklearn import svm, metrics\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.models as models\n",
        "\n",
        "# Define the data transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Download and load the Oxford-IIIT Pet dataset\n",
        "dataset = OxfordIIITPet(root='./', transform=transform, download=True)\n",
        "\n",
        "# Split the dataset into train and test sets (80% train, 20% test)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "# Define the data loader with different batches\n",
        "batch_size_train = 64\n",
        "batch_size_test = 16\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size_train, shuffle=True, num_workers=4)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size_test, shuffle=False, num_workers=4)\n",
        "\n",
        "# Check the length of train and test loaders\n",
        "print(\"Number of batches in train loader:\", len(train_loader))\n",
        "print(\"Number of batches in test loader:\", len(test_loader))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVc3h5mO2v1c"
      },
      "source": [
        "This code defines a custom dataset class named CustomDataset using PyTorch's torch.utils.data.Dataset.\n",
        "The custom dataset (`CustomDataset`) is designed for a machine learning task involving images of cats and dogs with different breeds. This dataset is implemented as a custom class in PyTorch, which extends the `torch.utils.data.Dataset` class. The purpose of this dataset is to provide an organized and customizable interface for loading and processing image data for machine learning tasks.\n",
        "\n",
        "Here are the key characteristics and functionalities of the `CustomDataset`:\n",
        "\n",
        "1. **Initialization:**\n",
        "   - The dataset is initialized with the root directory where the images are stored (`root_dir`) and an optional transformation for image preprocessing (`transform`).\n",
        "\n",
        "2. **Labeling:**\n",
        "   - The dataset automatically extracts labels (breeds) from the image filenames. It determines if an image represents a cat or a dog based on the first letter of the filename and extracts the breed accordingly.\n",
        "\n",
        "3. **Mapping Classes to Indices:**\n",
        "   - The dataset creates a mapping from class names (breeds) to numerical indices. This mapping is useful for machine learning models, as they typically require numerical labels.\n",
        "\n",
        "4. **Length of Dataset:**\n",
        "   - The `__len__` method is implemented to return the total number of images in the dataset.\n",
        "\n",
        "5. **Retrieving Samples:**\n",
        "   - The `__getitem__` method is implemented to retrieve and process a single sample at a given index. It loads the image, applies the specified transformation, determines the label, and returns the processed image and label.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ROrf4SK5jkZ"
      },
      "source": [
        " loading the train_dataset from a file, displaying an image from the dataset, printing its corresponding label, and checking the classes present in the dataset.\n",
        "Uses matplotlib.pyplot.imshow to display the image at index 1 in the dataset. The .permute(1, 2, 0) rearranges the dimensions of the tensor to match the expected order for displaying images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "r1YgV_ctrkkz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a7627e0-5e59-4d41-a4be-b6fc479d2ca4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 72.9MB/s]\n"
          ]
        }
      ],
      "source": [
        "resnet18 = models.resnet18(pretrained=True)\n",
        "# Remove the fully connected layers from the model\n",
        "resnet18 = nn.Sequential(*list(resnet18.children())[:-2])\n",
        "\n",
        "class ResNet18Features(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ResNet18Features, self).__init__()\n",
        "        self.resnet18 = resnet18\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.resnet18(x)\n",
        "\n",
        "# Create instances of ResNet18Features\n",
        "model_avgpool = nn.Sequential(*list(resnet18.children())[:-2])\n",
        "model_block1 = nn.Sequential(*list(resnet18.children())[:-6])\n",
        "model_block3 = nn.Sequential(*list(resnet18.children())[:-4])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-QUA9Ox62Vk"
      },
      "source": [
        "In this code segment, you modify the pre-trained ResNet-18 model by removing the fully connected layers, and then define a new neural network model (`ResNet18Features`) based on this modified ResNet-18. Additionally, three instances of this model are created with different names (`model_avgpool`, `model_block1`, and `model_block3`). Here's a detailed explanation:\n",
        "\n",
        "1. **Remove Fully Connected Layers from ResNet-18:**\n",
        "   ```python\n",
        "   resnet18 = nn.Sequential(*list(resnet18.children())[:-2])\n",
        "   ```\n",
        "\n",
        "   - This line creates a new `nn.Sequential` model by excluding the last two layers (fully connected layers) from the pre-trained ResNet-18 model. It effectively removes the classification layers, leaving only the feature extraction part.\n",
        "\n",
        "2. **Define `ResNet18Features` Model:**\n",
        "   ```python\n",
        "   class ResNet18Features(nn.Module):\n",
        "       def __init__(self):\n",
        "           super(ResNet18Features, self).__init__()\n",
        "           self.resnet18 = resnet18\n",
        "\n",
        "       def forward(self, x):\n",
        "           return self.resnet18(x)\n",
        "   ```\n",
        "\n",
        "   - Defines a new neural network model `ResNet18Features` that inherits from `nn.Module`. The `forward` method simply passes the input through the modified ResNet-18 model.\n",
        "\n",
        "3. **Create Instances of `ResNet18Features`:**\n",
        "   ```python\n",
        "   model_avgpool = ResNet18Features()\n",
        "   model_block1 = ResNet18Features()\n",
        "   model_block3 = ResNet18Features()\n",
        "   ```\n",
        "\n",
        "   - Three instances of the `ResNet18Features` model are created with different names (`model_avgpool`, `model_block1`, and `model_block3`). These instances can be used independently, each representing a modified ResNet-18 model without the fully connected layers.\n",
        "\n",
        "Overall, this code prepares modified ResNet-18 models for feature extraction. Depending on your task, you might use these models to extract features from different layers of the ResNet-18 architecture. For example, `model_avgpool` may be used to extract features after the average pooling layer, while `model_block1` and `model_block3` may be used to extract features after the first and third residual blocks, respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "g85_f_PNrsRi"
      },
      "outputs": [],
      "source": [
        "# Extract features from average pooling, block 1, and block 3\n",
        "import numpy as np\n",
        "def extract_features(model, loader):\n",
        "    features = []\n",
        "    labels = []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for images, targets in loader:\n",
        "            outputs = model(images)\n",
        "            features.append(outputs.squeeze().cpu().numpy())\n",
        "            labels.append(targets.cpu().numpy())\n",
        "\n",
        "    features = np.vstack(features)\n",
        "    labels = np.concatenate(labels)\n",
        "    return features, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wG_FHf8l74yJ"
      },
      "source": [
        "This code defines a function `extract_features` that takes a model and a data loader as input and extracts features from the specified model. The features are extracted for each batch in the data loader, and the final features and corresponding labels are returned as NumPy arrays. Here's a breakdown of the code:\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "def extract_features(model, loader):\n",
        "    features = []\n",
        "    labels = []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for images, targets in loader:\n",
        "            outputs = model(images)\n",
        "            features.append(outputs.squeeze().cpu().numpy())\n",
        "            labels.append(targets.cpu().numpy())\n",
        "\n",
        "    features = np.vstack(features)\n",
        "    labels = np.concatenate(labels)\n",
        "    return features, labels\n",
        "```\n",
        "\n",
        "- `model`: The neural network model from which features are to be extracted.\n",
        "- `loader`: The data loader containing the images and labels for which features need to be extracted.\n",
        "\n",
        "1. **Initialize Empty Lists:**\n",
        "   ```python\n",
        "   features = []\n",
        "   labels = []\n",
        "   ```\n",
        "\n",
        "   - Initialize empty lists to store the extracted features and corresponding labels.\n",
        "\n",
        "2. **Set Model to Evaluation Mode:**\n",
        "   ```python\n",
        "   model.eval()\n",
        "   ```\n",
        "\n",
        "   - Sets the model to evaluation mode. This is important because certain layers, such as dropout or batch normalization, behave differently during training and evaluation.\n",
        "\n",
        "3. **Iterate Through DataLoader Batches:**\n",
        "   ```python\n",
        "   with torch.no_grad():\n",
        "       for images, targets in loader:\n",
        "           outputs = model(images)\n",
        "           features.append(outputs.squeeze().cpu().numpy())\n",
        "           labels.append(targets.cpu().numpy())\n",
        "   ```\n",
        "\n",
        "   - Iterates through batches in the data loader. For each batch, it computes the model outputs and appends the features and labels to the respective lists. `torch.no_grad()` is used to disable gradient computation during inference, reducing memory usage.\n",
        "\n",
        "4. **Stack Features and Concatenate Labels:**\n",
        "   ```python\n",
        "   features = np.vstack(features)\n",
        "   labels = np.concatenate(labels)\n",
        "   ```\n",
        "\n",
        "   - Stacks the feature arrays vertically (along the first axis) to form the final feature array. Labels are concatenated along the first axis to form the final label array.\n",
        "\n",
        "5. **Return Extracted Features and Labels:**\n",
        "   ```python\n",
        "   return features, labels\n",
        "   ```\n",
        "\n",
        "   - Returns the extracted features and labels as NumPy arrays.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Vm42vQaosyee"
      },
      "outputs": [],
      "source": [
        "# Extract features from average pooling\n",
        "avgpool_features_train, avgpool_labels_train = extract_features(model_avgpool, train_loader)\n",
        "avgpool_features_val, avgpool_labels_val = extract_features(model_avgpool, test_loader)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract features from block 1\n",
        "block1_features_train, block1_labels_train = extract_features(model_block1, train_loader)\n",
        "block1_features_val, block1_labels_val = extract_features(model_block1, test_loader)\n",
        "\n"
      ],
      "metadata": {
        "id": "GYQkE2X6GshS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract features from block 3\n",
        "block3_features_train, block3_labels_train = extract_features(model_block3, train_loader)\n",
        "block3_features_val, block3_labels_val = extract_features(model_block3, test_loader)"
      ],
      "metadata": {
        "id": "vuu9ccVTGuNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zc7DTD9N8Vkc"
      },
      "source": [
        "Average Pooling Layer:\n",
        "\n",
        "Features are extracted from the model (model_avgpool) after the average pooling layer for both the training and validation sets. The extracted features and labels are stored in avgpool_features_train, avgpool_labels_train, avgpool_features_val, and avgpool_labels_val.\n",
        "Block 1:\n",
        "\n",
        "Features are extracted from the model (model_block1) after the first residual block for both the training and validation sets. The extracted features and labels are stored in block1_features_train, block1_labels_train, block1_features_val, and block1_labels_val.\n",
        "Block 3:\n",
        "\n",
        "Features are extracted from the model (model_block3) after the third residual block for both the training and validation sets. The extracted features and labels are stored in block3_features_train, block3_labels_train, block3_features_val, and block3_labels_val.\n",
        "These extracted features can be used as input to train a different classifier, such as a Support Vector Machine (SVM), or for any other downstream task. The separation of features from different layers allows for experimentation with different levels of abstraction in the feature representations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TfcGVnyBxRr4"
      },
      "outputs": [],
      "source": [
        "# Concatenate features from different blocks\n",
        "train_features = np.concatenate([avgpool_features_train, block1_features_train, block3_features_train], axis=1)\n",
        "val_features = np.concatenate([avgpool_features_val, block1_features_val, block3_features_val], axis=1)\n",
        "\n",
        "# Flatten the features\n",
        "train_features_flat = train_features.reshape(train_features.shape[0], -1)\n",
        "val_features_flat = val_features.reshape(val_features.shape[0], -1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukohY-YS8hKI"
      },
      "source": [
        "In this code, features extracted from different layers (average pooling, block 1, and block 3) are concatenated horizontally and then flattened. This is often done to create a single feature vector for each sample that can be used as input to a downstream classifier or model. Here's the breakdown:\n",
        "\n",
        "```python\n",
        "# Concatenate features from different blocks\n",
        "train_features = np.concatenate([avgpool_features_train, block1_features_train, block3_features_train], axis=1)\n",
        "val_features = np.concatenate([avgpool_features_val, block1_features_val, block3_features_val], axis=1)\n",
        "\n",
        "# Flatten the features\n",
        "train_features_flat = train_features.reshape(train_features.shape[0], -1)\n",
        "val_features_flat = val_features.reshape(val_features.shape[0], -1)\n",
        "```\n",
        "\n",
        "- **Concatenate Features:**\n",
        "  - The features extracted from different blocks (`avgpool_features_train`, `block1_features_train`, `block3_features_train`, etc.) are concatenated horizontally along axis 1 using `np.concatenate`. This creates a single array for each sample with features from different blocks side by side.\n",
        "\n",
        "- **Flatten the Features:**\n",
        "  - The concatenated feature arrays are flattened using `reshape` so that each sample's features are represented as a 1D array. This results in `train_features_flat` and `val_features_flat`, which can be used as inputs to a downstream classifier.\n",
        "\n",
        "The final `train_features_flat` and `val_features_flat` arrays can be used as input features for training a classifier, such as a Support Vector Machine (SVM) or any other machine learning model. The concatenation and flattening help create a unified representation of features from different layers for each sample.\n",
        "\n",
        "\n",
        "SVMs are robust and effective in high-dimensional spaces, making them suitable for various applications, including image classification, text classification, and bioinformatics. SVMs have been widely used in both binary and multi-class classification problems due to their ability to handle complex decision boundaries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9n1JcCXhxbY6"
      },
      "outputs": [],
      "source": [
        "print(train_features_flat.shape, val_features_flat.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oyvtzCzVxetD"
      },
      "outputs": [],
      "source": [
        "n_components = 2000  # You can adjust this value based on your requirements\n",
        "\n",
        "# Apply PCA to training features\n",
        "pca = PCA(n_components=n_components)\n",
        "train_features_pca = pca.fit_transform(train_features_flat)\n",
        "\n",
        "# Apply PCA to validation features\n",
        "val_features_pca = pca.transform(val_features_flat)\n",
        "print(train_features_pca.shape, val_features_pca.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esOtJ4az9GzJ"
      },
      "source": [
        "In this code, Principal Component Analysis (PCA) is applied to reduce the dimensionality of the training and validation features. PCA is a technique used for dimensionality reduction and can be especially useful when dealing with high-dimensional data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEP9Jzfk9N7j"
      },
      "source": [
        "n_components Definition:\n",
        "\n",
        "n_components is a hyperparameter that determines the number of principal components to retain after PCA. It controls the dimensionality of the reduced feature space. In this example, it is set to 2000, but you can adjust this value based on your specific requirements and the amount of variance you want to retain.\n",
        "Apply PCA to Training Features:\n",
        "\n",
        "PCA(n_components=n_components) initializes a PCA object with the specified number of components. fit_transform is then called on the training features (train_features_flat) to compute the principal components and transform the original features into the reduced feature space.\n",
        "Apply PCA to Validation Features:\n",
        "\n",
        "transform is used on the validation features (val_features_flat) to apply the same PCA transformation learned from the training set. It's important to use the same transformation on both training and validation sets to maintain consistency.\n",
        "Print the Resulting Shapes:\n",
        "\n",
        "The shapes of the resulting feature arrays after PCA transformation are printed to the console. This is useful for verifying the impact of PCA on the dimensionality of the data.\n",
        "After applying PCA, train_features_pca and val_features_pca are the reduced-dimensional representations of the original features. The number of columns in these arrays corresponds to the number of principal components specified by n_components. This dimensionality reduction is often performed to reduce computational complexity and potential overfitting, especially when working with high-dimensional data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t3ybtexVyHSu"
      },
      "outputs": [],
      "source": [
        "# Train an SVM with RBF kernel\n",
        "svm_model = SVC(kernel='rbf', max_iter=2000)\n",
        "svm_model.fit(train_features_pca, avgpool_labels_train)\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "predictions = svm_model.predict(val_features_pca)\n",
        "accuracy = accuracy_score(avgpool_labels_val, predictions)\n",
        "precision = precision_score(avgpool_labels_val, predictions, average='macro')\n",
        "recall = recall_score(avgpool_labels_val, predictions, average='macro')\n",
        "f1 = f1_score(avgpool_labels_val, predictions, average='macro')\n",
        "print(f'Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74YfqL1X_BAr"
      },
      "source": [
        "In this code snippet, a Support Vector Machine (SVM) with a Radial Basis Function (RBF) kernel is trained using the reduced-dimensional features obtained from PCA. The model is then evaluated on the validation set.\n",
        "Train SVM with RBF Kernel:\n",
        "\n",
        "svm_model = SVC(kernel='rbf', max_iter=2000) initializes an SVM model with an RBF (Radial Basis Function) kernel. max_iter is set to 2000, controlling the maximum number of iterations for optimization. The model is then trained using the fit method on the PCA-transformed training features (train_features_pca) and corresponding labels (avgpool_labels_train).\n",
        "Evaluate the Model on Validation Set:\n",
        "\n",
        "predictions = svm_model.predict(val_features_pca) uses the trained SVM model to make predictions on the PCA-transformed validation features (val_features_pca).\n",
        "Various evaluation metrics are computed, including accuracy, precision, recall, and F1-score, using functions from the sklearn.metrics module (accuracy_score, precision_score, recall_score, f1_score).\n",
        "Print Evaluation Metrics:\n",
        "\n",
        "The computed evaluation metrics (accuracy, precision, recall, and F1-score) are printed to the console.\n",
        "This code trains an SVM model with an RBF kernel on the reduced-dimensional features obtained from PCA and assesses its performance on the validation set. The choice of kernel and hyperparameters, such as max_iter, may need to be adjusted based on the characteristics of your data and the specific requirements of your task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIpJwBmN_LtF"
      },
      "source": [
        "The joblib.dump function is used to save the trained SVM model (svm_model) to a file named 'svm_model_resnet.pkl'. This allows you to persist the trained model so that you can later load it and use it for making predictions on new data without retraining the model.\n",
        " you will have a file named 'svm_model_resnet.pkl' containing the serialized representation of the trained SVM model. You can later load this model using joblib.load to make predictions on new data without having to retrain the model from scratch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kH-CfHACzDfj"
      },
      "outputs": [],
      "source": [
        "# plot the confusion matrix\n",
        "true_labels = avgpool_labels_val\n",
        "pred_labels = predictions\n",
        "\n",
        "cm = confusion_matrix(avgpool_labels_val, predictions)\n",
        "\n",
        "classes = train_dataset.dataset.classes\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(16, 12))\n",
        "sns.set(font_scale=1.2)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
        "\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbQtyQDF_x7k"
      },
      "source": [
        "This code generates and visualizes a confusion matrix using the true labels (avgpool_labels_val) and predicted labels (predictions) obtained from evaluating the SVM model on the validation set. The confusion matrix provides insights into the model's performance by showing the number of true positive, true negative, false positive, and false negative predictions for each class."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from PIL import Image\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix, roc_curve, roc_auc_score, auc\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import joblib\n",
        "from sklearn.decomposition import PCA\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.multiclass import OneVsRestClassifier\n"
      ],
      "metadata": {
        "id": "2OAdaY1BYb2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cH33oiWizL0e"
      },
      "outputs": [],
      "source": [
        "true_labels = avgpool_labels_val\n",
        "predicted_scores = svm_model.decision_function(val_features_pca)\n",
        "\n",
        "n_classes = len(train_dataset.dataset.classes)\n",
        "\n",
        "true_labels_bin = label_binarize(true_labels, classes=np.unique(true_labels))\n",
        "roc_auc_macro = roc_auc_score(true_labels_bin, predicted_scores, average='macro')\n",
        "print(f'Macro-average ROC AUC: {roc_auc_macro:.2f}')\n",
        "\n",
        "# Plot ROC curve for each class\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(true_labels_bin[:, i], predicted_scores[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.figure(figsize=(20, 16))\n",
        "for i in range(n_classes):\n",
        "    plt.plot(fpr[i], tpr[i], label=f'Class {i} (AUC = {roc_auc[i]:.2f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Random')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve for Multi-class Classification')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCDv8_ZfAO8b"
      },
      "source": [
        "Obtain True Labels and Predicted Scores:\n",
        "\n",
        "true_labels are the true class labels from the validation set.\n",
        "predicted_scores are the decision function values obtained from the SVM model.\n",
        "Convert True Labels to Binary Format:\n",
        "\n",
        "true_labels_bin converts the true class labels into a binary format suitable for multi-class ROC analysis using label_binarize from scikit-learn.\n",
        "Calculate Macro-average ROC AUC:\n",
        "\n",
        "roc_auc_macro computes the macro-average ROC AUC score, representing the overall performance across all classes.\n",
        "Plot ROC Curve for Each Class:\n",
        "\n",
        "For each class, ROC curves are computed (fpr, tpr) and the ROC AUC is calculated.\n",
        "Individual ROC curves are plotted for each class.\n",
        "Plot Random Line (Baseline):\n",
        "\n",
        "A dashed line representing random guessing (baseline) is added to the plot.\n",
        "Set Labels and Title:\n",
        "\n",
        "X-axis and Y-axis labels, as well as the title of the plot, are set.\n",
        "Display Legend:\n",
        "\n",
        "The legend is displayed in the lower right corner to identify each class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9L2jNJqGz7r2"
      },
      "outputs": [],
      "source": [
        "# Define the transformation to be applied to each image\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Load the saved datasets\n",
        "train_dataset = torch.load('/content/train_dataset.pth')\n",
        "val_dataset = torch.load('/content/val_dataset.pth')\n",
        "\n",
        "# Create DataLoader for training and validation sets\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJP_mUGH0FL6"
      },
      "outputs": [],
      "source": [
        "# Load pre-trained GoogLeNet (Inception) model\n",
        "googlenet = models.googlenet(pretrained=True)\n",
        "\n",
        "# Remove the fully connected layers from the model\n",
        "googlenet = nn.Sequential(*list(googlenet.children())[:-1])\n",
        "\n",
        "# Define the SVM model\n",
        "class GoogLeNetFeatures(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GoogLeNetFeatures, self).__init__()\n",
        "        self.googlenet = googlenet\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.googlenet(x)\n",
        "\n",
        "# Create instances of GoogLeNetFeatures\n",
        "model_inception3b = GoogLeNetFeatures()\n",
        "model_inception4e = GoogLeNetFeatures()\n",
        "model_avgpool = GoogLeNetFeatures()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCYI2rezAxzj"
      },
      "source": [
        "In this code, a pre-trained GoogLeNet (Inception) model is loaded, and features are extracted from specific layers of the model using the defined GoogLeNetFeatures class. The features are extracted separately for two different layers: 'inception3b' and 'inception4e', as well as from the 'AvgPool' layer.\n",
        "Load Pre-trained GoogLeNet Model:\n",
        "\n",
        "models.googlenet(pretrained=True) loads the pre-trained GoogLeNet model.\n",
        "Remove Fully Connected Layers:\n",
        "\n",
        "The fully connected layers are removed from the model using nn.Sequential(*list(googlenet.children())[:-1]).\n",
        "Define GoogLeNetFeatures Class:\n",
        "\n",
        "The GoogLeNetFeatures class is defined, which takes an input tensor and returns the features obtained from the GoogLeNet model.\n",
        "Create Instances of GoogLeNetFeatures:\n",
        "\n",
        "Instances of the GoogLeNetFeatures class are created for two different layers ('inception3b' and 'inception4e') and the 'AvgPool' layer.\n",
        "Extract Features from Inception (3b):\n",
        "\n",
        "Features are extracted from the 'inception3b' layer for both the training and validation sets.\n",
        "Extract Features from Inception (4e):\n",
        "\n",
        "Features are extracted from the 'inception4e' layer for both the training and validation sets.\n",
        "Extract Features from AvgPool:\n",
        "\n",
        "Features are extracted from the 'AvgPool' layer for both the training and validation sets.\n",
        "These extracted features can be used for downstream tasks, such as training a Support Vector Machine (SVM) or any other classification model. The separation of features from different layers allows for experimenting with different levels of abstraction in the feature representations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPvynqz60KW_"
      },
      "outputs": [],
      "source": [
        "# Extract features from Inception (3b)\n",
        "inception3b_features_train, inception3b_labels_train = extract_features(model_inception3b, train_loader)\n",
        "inception3b_features_val, inception3b_labels_val = extract_features(model_inception3b, val_loader)\n",
        "\n",
        "# Extract features from Inception (4e)\n",
        "inception4e_features_train, inception4e_labels_train = extract_features(model_inception4e, train_loader)\n",
        "inception4e_features_val, inception4e_labels_val = extract_features(model_inception4e, val_loader)\n",
        "\n",
        "# Extract features from AvgPool\n",
        "avgpool_features_train, avgpool_labels_train = extract_features(model_avgpool, train_loader)\n",
        "avgpool_features_val, avgpool_labels_val = extract_features(model_avgpool, val_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "duqFrSX8CBBv"
      },
      "outputs": [],
      "source": [
        "# Concatenate features from different Inception blocks\n",
        "train_features = np.concatenate([inception3b_features_train, inception4e_features_train, avgpool_features_train], axis=1)\n",
        "val_features = np.concatenate([inception3b_features_val, inception4e_features_val, avgpool_features_val], axis=1)\n",
        "\n",
        "# Flatten the features\n",
        "train_features_flat = train_features.reshape(train_features.shape[0], -1)\n",
        "val_features_flat = val_features.reshape(val_features.shape[0], -1)\n",
        "\n",
        "\n",
        "# Train an SVM with RBF kernel\n",
        "svm_model = SVC(kernel='rbf', max_iter=2000)\n",
        "svm_model.fit(train_features, inception3b_labels_train)  # You can choose any set of labels, e.g., inception3b_labels_train or inception4e_labels_train\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "predictions = svm_model.predict(val_features)\n",
        "accuracy = accuracy_score(inception3b_labels_val, predictions)  # You can choose any set of labels, e.g., inception3b_labels_val or inception4e_labels_val\n",
        "print(f\"Validation Accuracy: {accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Q0cocW1CRe6"
      },
      "outputs": [],
      "source": [
        "loaded_svm_model = joblib.dump(svm_model, './inception/svm_model_inception_features.joblib')\n",
        "# plot the confusion matrix\n",
        "true_labels = inception3b_labels_val\n",
        "pred_labels = predictions\n",
        "\n",
        "cm = confusion_matrix(inception3b_labels_val, predictions)\n",
        "\n",
        "classes = train_dataset.dataset.classes\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(16, 12))\n",
        "sns.set(font_scale=1.2)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
        "\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_BTLsGQBC2M4"
      },
      "outputs": [],
      "source": [
        "true_labels = inception3b_labels_val\n",
        "predicted_scores = svm_model.decision_function(val_features_flat)\n",
        "\n",
        "n_classes = len(train_dataset.dataset.classes)\n",
        "\n",
        "true_labels_bin = label_binarize(true_labels, classes=np.unique(true_labels))\n",
        "roc_auc_macro = roc_auc_score(true_labels_bin, predicted_scores, average='macro')\n",
        "print(f'Macro-average ROC AUC: {roc_auc_macro:.2f}')\n",
        "\n",
        "# Plot ROC curve for each class\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(true_labels_bin[:, i], predicted_scores[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.figure(figsize=(20, 16))\n",
        "for i in range(n_classes):\n",
        "    plt.plot(fpr[i], tpr[i], label=f'Class {i} (AUC = {roc_auc[i]:.2f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Random')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve for Multi-class Classification')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZVk-xUZWboF"
      },
      "outputs": [],
      "source": [
        "# Define the transformation to be applied to each image\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Load the saved datasets\n",
        "train_dataset = torch.load('/content/train_dataset.pth')\n",
        "val_dataset = torch.load('/content/val_dataset.pth')\n",
        "\n",
        "# Create DataLoader for training and validation sets\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59-1LgEoWpPP"
      },
      "outputs": [],
      "source": [
        "# Load pre-trained MobileNetV2 model\n",
        "mobilenet = models.mobilenet_v2(pretrained=True)\n",
        "\n",
        "# Remove the fully connected layers from the model\n",
        "mobilenet = nn.Sequential(*list(mobilenet.children())[:-1])\n",
        "\n",
        "# Define the SVM model\n",
        "class MobileNetV2Features(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MobileNetV2Features, self).__init__()\n",
        "        self.mobilenet = mobilenet\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.mobilenet(x)\n",
        "\n",
        "# Create instances of MobileNetV2Features\n",
        "model_avgpool = MobileNetV2Features()\n",
        "model_conv1 = MobileNetV2Features()\n",
        "model_middle_layer = MobileNetV2Features()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePYhjpvHBVwe"
      },
      "source": [
        "\n",
        "In this code, a pre-trained MobileNetV2 model is loaded, and the fully connected layers are removed from the model. Then, three instances of the MobileNetV2Features class are created, each designed to extract features from different layers of the MobileNetV2 model.\n",
        "Load Pre-trained MobileNetV2 Model:\n",
        "\n",
        "models.mobilenet_v2(pretrained=True) loads the pre-trained MobileNetV2 model.\n",
        "Remove Fully Connected Layers:\n",
        "\n",
        "The fully connected layers are removed from the model using nn.Sequential(*list(mobilenet.children())[:-1]).\n",
        "Define MobileNetV2Features Class:\n",
        "\n",
        "The MobileNetV2Features class is defined, which takes an input tensor and returns the features obtained from the MobileNetV2 model.\n",
        "Create Instances of MobileNetV2Features:\n",
        "\n",
        "Three instances of the MobileNetV2Features class are created: model_avgpool, model_conv1, and model_middle_layer.\n",
        "These instances can be used to extract features from different layers of the MobileNetV2 model. The choice of layers (AvgPool, Conv1, Middle Layer, etc.) allows for experimenting with different levels of abstraction in the feature representations. These extracted features can be further utilized for tasks such as classification, feature analysis, or other downstream applications."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDJL_k7sXAO_"
      },
      "outputs": [],
      "source": [
        "def extract_features_labels(model, loader):\n",
        "    features = []\n",
        "    labels = []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for images, targets in loader:\n",
        "            outputs = model(images)\n",
        "            features.append(outputs.squeeze().cpu().numpy())\n",
        "            labels.append(targets.cpu().numpy())\n",
        "\n",
        "    features = np.vstack(features)\n",
        "    labels = np.concatenate(labels)\n",
        "    return features, labels\n",
        "# Extract features from AvgPool\n",
        "avgpool_features_train, avgpool_labels_train = extract_features_labels(model_avgpool, train_loader)\n",
        "avgpool_features_val, avgpool_labels_val = extract_features_labels(model_avgpool, val_loader)\n",
        "\n",
        "np.save('mobile_avgpool_features_train.npy', avgpool_features_train)\n",
        "np.save('mobile_avgpool_labels_train.npy', avgpool_labels_train)\n",
        "np.save('mobile_avgpool_features_val.npy', avgpool_features_val)\n",
        "np.save('mobile_avgpool_labels_val.npy', avgpool_labels_val)\n",
        "avgpool_features_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h4pSFtVvXJSV"
      },
      "outputs": [],
      "source": [
        "# Extract features from Conv1\n",
        "conv1_features_train, conv1_labels_train = extract_features_labels(model_conv1, train_loader)\n",
        "conv1_features_val, conv1_labels_val = extract_features_labels(model_conv1, val_loader)\n",
        "# Save the extracted features and labels to .npy files\n",
        "np.save('mobile_features_train.npy', conv1_features_train)\n",
        "np.save('mobile_labels_train.npy', conv1_labels_train)\n",
        "np.save('mobile_features_val.npy', conv1_features_val)\n",
        "np.save('mobile_labels_val.npy', conv1_labels_val)\n",
        "conv1_features_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3h0IgqMQXMaT"
      },
      "outputs": [],
      "source": [
        "# Extract features from the middle layer\n",
        "middle_layer_features_train, middle_layer_labels_train = extract_features_labels(model_middle_layer, train_loader)\n",
        "middle_layer_features_val, middle_layer_labels_val = extract_features_labels(model_middle_layer, val_loader)\n",
        "\n",
        "np.save('mobile_middle_features_train.npy', middle_layer_features_train)\n",
        "np.save('mobile_middle_labels_train.npy', middle_layer_labels_train)\n",
        "np.save('mobile_middle_features_val.npy', middle_layer_features_val)\n",
        "np.save('mobile_middle_labels_val.npy', middle_layer_labels_val)\n",
        "middle_layer_features_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8S59LqThZ5kn"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Concatenate features from different layers\n",
        "train_features = np.concatenate([avgpool_features_train, conv1_features_train, middle_layer_features_train], axis=1)\n",
        "val_features = np.concatenate([avgpool_features_val, conv1_features_val, middle_layer_features_val], axis=1)\n",
        "\n",
        "\n",
        "# Flatten the features\n",
        "train_features_flat = train_features.reshape(train_features.shape[0], -1)\n",
        "val_features_flat = val_features.reshape(val_features.shape[0], -1)\n",
        "\n",
        "# empty train_features and val_features\n",
        "train_features = None\n",
        "val_features = None\n",
        "avgpool_features_train = None\n",
        "avgpool_features_val = None\n",
        "conv1_features_train = None\n",
        "conv1_features_val = None\n",
        "middle_layer_features_train = None\n",
        "middle_layer_features_val = None\n",
        "n_components = 1000  # You can adjust this value based on your requirements\n",
        "\n",
        "# Apply PCA to training features\n",
        "pca = PCA(n_components=n_components)\n",
        "train_features_pca = pca.fit_transform(train_features_flat)\n",
        "\n",
        "# Apply PCA to validation features\n",
        "val_features_pca = pca.transform(val_features_flat)\n",
        "# Train an SVM with RBF kernel\n",
        "svm_model = SVC(kernel='rbf', max_iter=3000)\n",
        "svm_model.fit(train_features_pca, avgpool_labels_train)  # You can choose any set of labels, e.g., avgpool_labels_train or conv1_labels_train\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "predictions = svm_model.predict(val_features_pca)\n",
        "accuracy = accuracy_score(avgpool_labels_val, predictions)  # You can choose any set of labels, e.g., avgpool_labels_val or conv1_labels_val\n",
        "print(f\"Validation Accuracy: {accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLtlpqw2x1Lr"
      },
      "outputs": [],
      "source": [
        "precision_score = precision_score(avgpool_labels_val, predictions, average='macro')\n",
        "recall_score = recall_score(avgpool_labels_val, predictions, average='macro')\n",
        "f1_score = f1_score(avgpool_labels_val, predictions, average='macro')\n",
        "\n",
        "print(f\"Precision Score: {precision_score}, Recall Score: {recall_score}, F1 Score: {f1_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aS0xelq9x7or"
      },
      "outputs": [],
      "source": [
        "# plot the confusion matrix\n",
        "true_labels = avgpool_labels_train\n",
        "pred_labels = predictions\n",
        "\n",
        "cm = confusion_matrix(avgpool_labels_val, predictions)\n",
        "\n",
        "classes = train_dataset.dataset.classes\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(16, 12))\n",
        "sns.set(font_scale=1.2)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
        "\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9PUejWGyCq9"
      },
      "outputs": [],
      "source": [
        "true_labels = avgpool_labels_val\n",
        "predicted_scores = svm_model.decision_function(val_features_pca)\n",
        "\n",
        "n_classes = len(train_dataset.dataset.classes)\n",
        "\n",
        "true_labels_bin = label_binarize(true_labels, classes=np.unique(true_labels))\n",
        "roc_auc_macro = roc_auc_score(true_labels_bin, predicted_scores, average='macro')\n",
        "print(f'Macro-average ROC AUC: {roc_auc_macro:.2f}')\n",
        "\n",
        "# Plot ROC curve for each class\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(true_labels_bin[:, i], predicted_scores[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.figure(figsize=(20, 16))\n",
        "for i in range(n_classes):\n",
        "    plt.plot(fpr[i], tpr[i], label=f'Class {i} (AUC = {roc_auc[i]:.2f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Random')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve for Multi-class Classification')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzVZvgCNo3v7"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define the neural network model for MobileNetV2\n",
        "class NetMobile(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NetMobile, self).__init__()\n",
        "        self.mobile_net = models.mobilenet_v2(pretrained=True)\n",
        "        self.mobile_net.features[0][0] = nn.Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "        # Print the architecture to identify the correct layer index\n",
        "        print(self.mobile_net.features)\n",
        "\n",
        "        # Extract features from the desired layers\n",
        "        output_avgpool = avgpool(self.mobile_net.features(x))\n",
        "\n",
        "        # Adjust the index to access the desired layer within InvertedResidual block\n",
        "        output_mid = self.mobile_net.features[4][0][3].conv[1](self.mobile_net.features[4][0][0](x))\n",
        "\n",
        "        return output_avgpool, output_mid\n",
        "\n",
        "\n",
        "\n",
        "# Instantiate the model and set it to evaluation mode\n",
        "\n",
        "\n",
        "model_mobile = NetMobile()\n",
        "model_mobile.eval()\n",
        "\n",
        "# Extract features using the model\n",
        "def extract_mobile_features(loader):\n",
        "    all_avgpool, all_mid = [], []\n",
        "    with torch.no_grad():\n",
        "        for data, _ in loader:\n",
        "            avgpool, mid = model_mobile(data)\n",
        "            all_avgpool.append(avgpool)\n",
        "            all_mid.append(mid)\n",
        "\n",
        "    return torch.cat(all_avgpool), torch.cat(all_mid)\n",
        "\n",
        "# Extract features for training and testing sets\n",
        "train_avgpool, train_mid = extract_mobile_features(train_loader)\n",
        "test_avgpool, test_mid = extract_mobile_features(test_loader)\n",
        "\n",
        "# Concatenate features\n",
        "X_train = torch.cat([train_avgpool, train_mid], dim=1).numpy()\n",
        "X_test = torch.cat([test_avgpool, test_mid], dim=1).numpy()\n",
        "\n",
        "# Placeholder for labels (replace with your actual labels)\n",
        "y_train = torch.zeros(train_avgpool.shape[0]).numpy()\n",
        "y_test = torch.zeros(test_avgpool.shape[0]).numpy()\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Train SVM model with RBF kernel\n",
        "svm_mobile = svm.SVC(kernel='rbf')\n",
        "svm_mobile.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = svm_mobile.predict(X_test)\n",
        "\n",
        "# Calculate confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "# Calculate ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc))\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DE5Zm1EUCunf"
      },
      "outputs": [],
      "source": [
        "!pip install scikit-learn matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrgBa3oADpaM"
      },
      "source": [
        "Phase 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0XdpoSTFp4q"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming you have a CustomDataset class and models (model_avgpool, model_conv1, model_middle_layer) defined\n",
        "\n",
        "# Define the transformation to be applied to each image\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "\n",
        "# Load the dataset\n",
        "# dataset = CustomDataset(root_dir='path_to_your_dataset', transform=transform)\n",
        "data_loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "# Extract features from the 'AvgPool' layer of the model\n",
        "def extract_avgpool_features(model, loader):\n",
        "    features = []\n",
        "    labels = []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for images, targets in loader:\n",
        "            outputs = model(images)\n",
        "            features.append(outputs.squeeze().cpu().numpy())\n",
        "            labels.append(targets.cpu().numpy())\n",
        "\n",
        "    features = np.vstack(features)\n",
        "    labels = np.concatenate(labels)\n",
        "    return features, labels\n",
        "\n",
        "features_avgpool, labels = extract_avgpool_features(model_avgpool, data_loader)\n",
        "# Flatten the features for each image\n",
        "flattened_features_avgpool = features_avgpool.reshape(features_avgpool.shape[0], -1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZ39FhOiC6JT"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Apply k-means clustering\n",
        "n_clusters = 5  # Adjust as needed\n",
        "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "\n",
        "# Reshape the features to make them 2D\n",
        "features_2d = features_avgpool.reshape(features_avgpool.shape[0], -1)\n",
        "\n",
        "# Perform k-means clustering\n",
        "cluster_assignments = kmeans.fit_predict(features_2d)\n",
        "\n",
        "# Continue with the rest of your code\n",
        "\n",
        "\n",
        "# Select several images from the dataset (e.g., indices)\n",
        "selected_image_indices = [0, 10, 20]\n",
        "\n",
        "# Compare each selected image with its cluster representative\n",
        "for idx in selected_image_indices:\n",
        "    # Extract features from AvgPool for the selected image\n",
        "    selected_image_features = features_avgpool[idx].reshape(1, -1)\n",
        "\n",
        "    # Calculate distances to cluster centroids\n",
        "    distances = np.linalg.norm(selected_image_features - kmeans.cluster_centers_, axis=1)\n",
        "\n",
        "    # Find the cluster with the nearest centroid\n",
        "    nearest_cluster = np.argmin(distances)\n",
        "\n",
        "    # Display the selected image\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(dataset[idx][0].permute(1, 2, 0))\n",
        "    plt.title('Selected Image')\n",
        "\n",
        "    # Display the representative image of the nearest cluster\n",
        "    representative_image_idx = np.argmin(distances)\n",
        "    representative_image_path = dataset.image_files[np.where(cluster_assignments == nearest_cluster)[0][0]]\n",
        "    representative_image = Image.open(os.path.join('path_to_your_dataset', representative_image_path)).convert(\"RGB\")\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(representative_image)\n",
        "    plt.title(f'Representative Image (Cluster {nearest_cluster})')\n",
        "\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pb16F1ZvSayZ"
      },
      "outputs": [],
      "source": [
        "train_features = np.concatenate([avgpool_features_train, block1_features_train, block3_features_train], axis=1)\n",
        "val_features = np.concatenate([avgpool_features_val, block1_features_val, block3_features_val], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UVJGVXd8TwtC"
      },
      "outputs": [],
      "source": [
        "# Load the extracted features and labels from .npy files\n",
        "avgpool_features_train = np.load('/content/resnet_output/avgpool_features_train.npy')\n",
        "avgpool_labels_train = np.load('/content/resnet_output/avgpool_labels_train.npy')\n",
        "avgpool_features_val = np.load('/content/resnet_output/avgpool_features_val.npy')\n",
        "avgpool_labels_val = np.load('/content/resnet_output/avgpool_labels_val.npy')\n",
        "\n",
        "block1_features_train = np.load('/content/resnet_output/block1_features_train.npy')\n",
        "block1_labels_train = np.load('/content/resnet_output/block1_labels_train.npy')\n",
        "block1_features_val = np.load('/content/resnet_output/block1_features_val.npy')\n",
        "block1_labels_val = np.load('/content/resnet_output/block1_labels_val.npy')\n",
        "\n",
        "block3_features_train = np.load('/content/resnet_output/block3_features_train.npy')\n",
        "block3_labels_train = np.load('/content/resnet_output/block3_labels_train.npy')\n",
        "block3_features_val = np.load('/content/resnet_output/block3_features_val.npy')\n",
        "block3_labels_val = np.load('/content/resnet_output/block3_labels_val.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ybhe-G0iTyjb"
      },
      "outputs": [],
      "source": [
        "# Concatenate features from different blocks\n",
        "train_features = np.concatenate([avgpool_features_train, block1_features_train, block3_features_train], axis=1)\n",
        "val_features = np.concatenate([avgpool_features_val, block1_features_val, block3_features_val], axis=1)\n",
        "\n",
        "# Flatten the features\n",
        "train_features_flat = train_features.reshape(train_features.shape[0], -1)\n",
        "val_features_flat = val_features.reshape(val_features.shape[0], -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OOslgdXgUH_R"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "\n",
        "# Concatenate features from different layers\n",
        "train_features = np.concatenate([avgpool_features_train, block1_features_train, block3_features_train], axis=1)\n",
        "\n",
        "# Flatten the features\n",
        "train_features_flat = train_features.reshape(train_features.shape[0], -1)\n",
        "\n",
        "# Apply k-means clustering to training features\n",
        "n_clusters = 5  # You can adjust this based on your requirements\n",
        "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "cluster_assignments = kmeans.fit_predict(train_features_flat)\n",
        "\n",
        "# The rest of your code remains the same...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtvw3j0IKmBB"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assume you have already loaded the features and labels\n",
        "# avgpool_features_train, block1_features_train, block3_features_train, etc.\n",
        "\n",
        "# Concatenate features from different layers\n",
        "train_features = np.concatenate([avgpool_features_train, block1_features_train, block3_features_train], axis=1)\n",
        "val_features = np.concatenate([avgpool_features_val, block1_features_val, block3_features_val], axis=1)\n",
        "\n",
        "# Flatten the features\n",
        "train_features_flat = train_features.reshape(train_features.shape[0], -1)\n",
        "val_features_flat = val_features.reshape(val_features.shape[0], -1)\n",
        "\n",
        "# Apply k-means clustering to training features\n",
        "n_clusters = 5  # You can adjust this based on your requirements\n",
        "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "cluster_assignments = kmeans.fit_predict(train_features_flat)\n",
        "\n",
        "# Select several images from the validation set (e.g., indices)\n",
        "selected_image_indices = [0, 10, 20]\n",
        "\n",
        "# Compare each selected image with its cluster representative\n",
        "for idx in selected_image_indices:\n",
        "    # Extract features from MobileNetV2 for the selected image\n",
        "    selected_image_features = val_features_flat[idx].reshape(1, -1)\n",
        "\n",
        "    # Calculate distances to cluster centroids\n",
        "    distances = np.linalg.norm(selected_image_features - kmeans.cluster_centers_, axis=1)\n",
        "\n",
        "    # Find the cluster with the nearest centroid\n",
        "    nearest_cluster = np.argmin(distances)\n",
        "\n",
        "    # Display the selected image\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(val_dataset[idx][0].permute(1, 2, 0))\n",
        "    plt.title('Selected Image')\n",
        "\n",
        "    # Display the representative image of the nearest cluster\n",
        "    representative_images = train_features_flat[cluster_assignments == nearest_cluster]\n",
        "    representative_image = representative_images.mean(axis=0)\n",
        "    representative_image = representative_image.reshape(train_features.shape[1:3])  # Use the original shape\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(representative_image, cmap='viridis')  # Use an appropriate colormap\n",
        "    plt.title(f'Representative Image (Cluster {nearest_cluster})')\n",
        "\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KXkdRryQ4dkB"
      },
      "outputs": [],
      "source": [
        "resnet_avgpool_labels_train = np.load('res-net/avgpool_labels_train.npy')\n",
        "resnet_avgpool_features_train = np.load('res-net/avgpool_features_train.npy')\n",
        "resnet_avgpool_features_val = np.load('res-net/avgpool_features_val.npy')\n",
        "resnet_avgpool_labels_val = np.load('res-net/avgpool_labels_val.npy')\n",
        "\n",
        "inception_avgpool_labels_train = np.load('inception/inception_avgpool_labels_train.npy')\n",
        "inception_avgpool_features_train = np.load('inception/inception_avgpool_features_train.npy')\n",
        "inception_avgpool_features_val = np.load('inception/inception_avgpool_features_val.npy')\n",
        "inception_avgpool_labels_val = np.load('inception/inception_avgpool_labels_val.npy')\n",
        "\n",
        "mobilenet_avgpool_labels_train = np.load('mobile-net/mobile_avgpool_labels_train.npy')\n",
        "mobilenet_avgpool_features_train = np.load('mobile-net/mobile_avgpool_features_train.npy')\n",
        "mobilenet_avgpool_features_val = np.load('mobile-net/mobile_avgpool_features_val.npy')\n",
        "mobilenet_avgpool_labels_val = np.load('mobile-net/mobile_avgpool_labels_val.npy')\n",
        "print(\"resnet_avgpool_features_train.shape\", resnet_avgpool_features_train.shape)\n",
        "print(\"inception_avgpool_features_train.shape\", inception_avgpool_features_train.shape)\n",
        "print(\"mobilenet_avgpool_features_train.shape\", mobilenet_avgpool_features_train.shape)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}